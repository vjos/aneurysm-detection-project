{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib ipympl\n",
    "\n",
    "import dotenv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from intra import IntrA\n",
    "from models.pointnet import PointNetCls\n",
    "from models.pointnetcls import PointNet\n",
    "from models.pointnet2 import PointNet2\n",
    "from models.pointconv import PointConvDensityClsSsg\n",
    "from utils import train_model, train_kfold_intra, eval_model_classification\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "dotenv.load_dotenv()  # load the MLflow http authentication parameters\n",
    "mlflow.set_tracking_uri(os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "\n",
    "dev = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    #Â train pointnet for a single epoch to test utils on a slow laptop\n",
    "    dataset = IntrA(\n",
    "        \"./data\",\n",
    "        npoints=1024,\n",
    "        exclude_seg=True,\n",
    "        norm=True,\n",
    "        dataset=\"generated\",\n",
    "    )\n",
    "\n",
    "    trn, tst = torch.utils.data.random_split(dataset, [0.8, 0.2], torch.Generator().manual_seed(42))\n",
    " \n",
    "    model = PointNet(k=2)\n",
    "\n",
    "    train_dl = DataLoader(trn, batch_size=8, drop_last=True)\n",
    "    test_dl = DataLoader(tst, batch_size=8, drop_last=True)\n",
    "\n",
    "    train_model(model, train_dl, test_dl, epochs=1, checkpoint_epoch=50, model_name=\"PointNet\", norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1:\n",
      "Epoch: 1\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jventers/miniconda3/envs/masters-env/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_kfold_intra(\n\u001b[1;32m      2\u001b[0m     PointNet,\n\u001b[1;32m      3\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mk\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m2\u001b[39;49m},\n\u001b[1;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPointNet\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     num_workers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     intra_root\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./data\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     npoints\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     norm\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     11\u001b[0m     pointconv\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     12\u001b[0m     splits\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./file_splits/cls/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     exclude_seg\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/masters-project/project/utils.py:175\u001b[0m, in \u001b[0;36mtrain_kfold_intra\u001b[0;34m(model_class, model_kwargs, epochs, batch_size, num_workers, norm, pointconv, checkpoint_epoch, model_name, intra_root, npoints, exclude_seg, snapshot_path, splits)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    173\u001b[0m train_step(model, scheduler, optimizer, train_dl, pointconv\u001b[39m=\u001b[39mpointconv)\n\u001b[0;32m--> 175\u001b[0m train_metrics \u001b[39m=\u001b[39m eval_model_classification(\n\u001b[1;32m    176\u001b[0m     model, train_dl, norm\u001b[39m=\u001b[39;49mnorm, prefix\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m{\u001b[39;49;00mfold\u001b[39m}\u001b[39;49;00m\u001b[39m_train_\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    177\u001b[0m )\n\u001b[1;32m    179\u001b[0m test_metrics \u001b[39m=\u001b[39m eval_model_classification(\n\u001b[1;32m    180\u001b[0m     model, test_dl, norm\u001b[39m=\u001b[39mnorm, prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m_test_\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m )\n\u001b[1;32m    183\u001b[0m \u001b[39m# log all epoch metrics to mlflow\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/masters-project/project/utils.py:232\u001b[0m, in \u001b[0;36meval_model_classification\u001b[0;34m(model, data, prefix, norm)\u001b[0m\n\u001b[1;32m    229\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(dev)\n\u001b[1;32m    231\u001b[0m \u001b[39m# generate predictions on batch and check prediction equality to groundtruths\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m correct \u001b[39m=\u001b[39m run_model(model, pcld, norm\u001b[39m=\u001b[39;49mnorm)\u001b[39m.\u001b[39meq(label\u001b[39m.\u001b[39mdata)\n\u001b[1;32m    234\u001b[0m \u001b[39m# sum TPs and total occurences for each class in the batch\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39mfor\u001b[39;00m c, l \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(correct, label):\n",
      "File \u001b[0;32m~/Documents/masters-project/project/utils.py:215\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(model, pcld, norm)\u001b[0m\n\u001b[1;32m    212\u001b[0m pcld \u001b[39m=\u001b[39m pcld\u001b[39m.\u001b[39mto(dev)\n\u001b[1;32m    214\u001b[0m \u001b[39mif\u001b[39;00m norm:\n\u001b[0;32m--> 215\u001b[0m     pred \u001b[39m=\u001b[39m model(pcld[:, :\u001b[39m3\u001b[39;49m, :], pcld[:, \u001b[39m3\u001b[39;49m:, :])\n\u001b[1;32m    216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     pred \u001b[39m=\u001b[39m model(pcld)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/masters-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "train_kfold_intra(\n",
    "    PointNet,\n",
    "    {\"k\":2},\n",
    "    epochs=1,\n",
    "    model_name=\"PointNet\",\n",
    "    batch_size=8,\n",
    "    num_workers=2,\n",
    "    intra_root=\"./data\",\n",
    "    npoints=1024,\n",
    "    norm=True,\n",
    "    pointconv=False,\n",
    "    splits=\"./file_splits/cls/\",\n",
    "    exclude_seg=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
